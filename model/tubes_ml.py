# -*- coding: utf-8 -*-
"""tubes_ml.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bltZ3e-LyIJKpPS8MhxoKdsbOk8Fi-pa

# Identitas

Tiffany Tasya Agatha / 6182201017

Model Prediksi Regresi Harga Rumah

# Exploratory Data
"""

# Library yang dibutuhkan
import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns

from statsmodels.formula.api import ols
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import GradientBoostingRegressor
from xgboost import XGBRegressor

# Import dataset
HousePrice = pd.read_csv('/content/drive/MyDrive/6th/ML/tubes/House Prices.csv')
HousePrice.head(30)

"""Pengecekan baris, kolom, dan tipe data dari dataset"""

# Pengecekan setiap kolom pada dataset
HousePrice.info()

"""Pengecekan duplikat pada dataset"""

HousePrice.duplicated().sum()

"""Pengecekan kolom-kolom yang memiliki missing value"""

# Kolom missing value
print(HousePrice.isna().sum()[HousePrice.isna().sum() > 0])

"""Pengisian kolom yang missing value berdasarkan tipe data"""

# Pengisian kolom tipe data kategorikal dengan None
HousePrice = HousePrice.fillna({
    col: "None" for col in HousePrice.select_dtypes(include="object").columns})

# Pengisian kolom tipe data numerik dengan nilai 0
HousePrice = HousePrice.fillna({
    col: 0 for col in HousePrice.select_dtypes(include=["int64", "float64"]).columns})

# Verifikasi bahwa sudah tidak ada lagi missing value
null_colums = HousePrice.columns[HousePrice.isna().any()]
null_colums

"""Pembungan baris `Id` dan `GarageYrBlt`.


*   `Id` dibuang karena hanya atribut unique identifier
*   `GarageYrBlt` dibuang karena representasi nilai 0 tidak sesuai dengan deskripsi bahwa garasi tidak pernah dibangun yang menandakan bahwa rumah tersebut tidak punya garasi.


"""

# Pembuangan kolom
clean_HousePrice = HousePrice.drop(['Id', 'GarageYrBlt'], axis='columns')
clean_HousePrice.info()

"""## Split Categorical & Numerical Attributes"""

# Dataframe untuk kolom tipe kategorikal
categorical_df = clean_HousePrice.select_dtypes(exclude=np.number)
categorical_df.info()

# Dataframe untuk kolom tipe numerik
numeric_df = clean_HousePrice.select_dtypes(include=np.number)
numeric_df.info()

"""# Feature Enggineering

## Corellation Categorical

Menentukan atribut kategorikal yang memiliki korelasi yang kuat dengan atirbut `SalePrice` menggunakan metode ANOVA.
"""

# Inisialisasi fitur yang terpilih
feature_selected = []

# Inisilisasi disctionary untuk hasil metode ANOVA
categorical_corr = {}

# Looping untuk pengecekan anova dengan atribut SalePrice
for cat_col in categorical_df.columns:
  model = ols(f'SalePrice ~ C({cat_col})', data=clean_HousePrice).fit()
  anova_table = sm.stats.anova_lm(model, typ=2)
  categorical_corr[cat_col] = anova_table['PR(>F)'].iloc[0]

# Mengurutkan berdasarkan p-value terkecil - terbesar
categorical_corr = dict(sorted(categorical_corr.items(), key=lambda item: item[1]))

# Print out hasil
for key in categorical_corr.keys():
  if categorical_corr[key] < 0.05:
    print(key, categorical_corr[key])

"""Berdasarkan hasil ANOVA, terpilih 5 atribut yang memiliki nilai p-value terkecil."""

# Input 5 atribut terpilih
feature_selected.extend(['Neighborhood', 'ExterQual', 'BsmtQual', 'KitchenQual', 'GarageFinish'])

"""#### Visualisasi"""

# Atur urutan kategori yang diinginkan
order1 = ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex']

# Plot bar chart dengan atribut ExterQual dan Rata-Rata SalePrice
plt.figure(figsize=(10, 6))
sns.barplot(data=clean_HousePrice, x='ExterQual', y='SalePrice', estimator='mean', order=order1)
plt.title('Rata-rata SalePrice berdasarkan ExterQual', fontsize=14)
plt.ylabel('Rata-rata SalePrice')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Plot bar chart dengan BsmtQual dan Rata-Rata SalePrice
plt.figure(figsize=(10, 6))
sns.barplot(data=clean_HousePrice, x='BsmtQual', y='SalePrice', estimator='mean', order=order1)
plt.title('Rata-rata SalePrice berdasarkan BsmtQual', fontsize=14)
plt.ylabel('Rata-rata SalePrice')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Plot bar chart dengan KitchenQual dan Rata-Rata SalePrice
plt.figure(figsize=(10, 6))
sns.barplot(data=clean_HousePrice, x='KitchenQual', y='SalePrice', estimator='mean', order=order1)
plt.title('Rata-rata SalePrice berdasarkan KitchenQual', fontsize=14)
plt.ylabel('Rata-rata SalePrice')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Atur urutan kategori yang diinginkan
order2 = ['None', 'NA', 'Unf', 'RFn', 'Fin']

# Plot bar chart dengan GarageFinish dan Rata-Rata SalePrice
plt.figure(figsize=(10, 6))
sns.barplot(data=clean_HousePrice, x='GarageFinish', y='SalePrice', estimator='mean', order=order2)
plt.title('Rata-rata SalePrice berdasarkan GarageFinish', fontsize=14)
plt.ylabel('Rata-rata SalePrice')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Rata-Rata SalePrice per Neighborhood yang diurutkan dari terkecil - terbesar
ordered_neighborhoods = clean_HousePrice.groupby('Neighborhood')['SalePrice'].mean().sort_values().index

# Buat bar plot dengan urutan terurut
plt.figure(figsize=(12, 6))
sns.barplot(
    data=clean_HousePrice,
    x='Neighborhood',
    y='SalePrice',
    estimator='mean',
    order=ordered_neighborhoods
)
plt.title('Rata-rata SalePrice berdasarkan Neighborhood', fontsize=14)
plt.ylabel('Rata-rata SalePrice')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""#### Transformation Categorical Atributtes"""

# Pengecekan unique value dari setiap kolom kategorikal
for cat_col in feature_selected:
  unique_values = clean_HousePrice[cat_col].value_counts().index
  print(cat_col)
  print(unique_values)
  print()

# Buat mapping dari nama Neighborhood ke angka sesuai urutan rata-rata harga rumah
neighborhood_mapping = {name: idx for idx, name in enumerate(ordered_neighborhoods)}

# Ubah kolom 'Neighborhood' ke nilai label encoding
clean_HousePrice['Neighborhood'] = clean_HousePrice['Neighborhood'].map(neighborhood_mapping)

# Buat mapping untuk fitur ExterQual, KitchenQual, BsmtQual
encode = {
    'None': 0,
    'Po': 1, # poor
    'Fa': 2, # fair
    'TA': 3, # average
    'Gd': 4, # good
    'Ex': 5 # excellent
}
# Perubahan kolom
clean_HousePrice['ExterQual'] = clean_HousePrice['ExterQual'].map(encode)
clean_HousePrice['KitchenQual'] = clean_HousePrice['KitchenQual'].map(encode)
clean_HousePrice['BsmtQual'] = clean_HousePrice['BsmtQual'].map(encode)

# Buat mapping untuk fitur GarageFinish
encode = {
    'None': 0,
    'NA': 0, # no garage
    'Unf': 1, # unfinished
    'RFn': 2, # rough finished
    'Fin': 3 # finished
}
# Perubahan kolom
clean_HousePrice['GarageFinish'] = clean_HousePrice['GarageFinish'].map(encode)

# Verifikasi bahwa semua kolom sudah berubah
for cat_col in feature_selected:
  unique_values = clean_HousePrice[cat_col].value_counts().index
  print(cat_col)
  print(unique_values)
  print()

"""## Numeric

Menentukan atribut numerik yang memiliki korelasi yang kuat dengan atirbut `SalePrice` menggunakan metode Spearman Correlation.
"""

numeric_corr = numeric_df.corr(method='spearman')['SalePrice']
numeric_corr = numeric_corr.sort_values(ascending=False)
print(numeric_corr)

# Memilih fitur yang memiliki nilai korelasi diatas 0.60
feature_selected.extend(['OverallQual', 'GrLivArea', 'GarageCars', 'YearBuilt', 'GarageArea', 'FullBath', 'TotalBsmtSF'])

"""#### Visualisasi

Visualisasi HeatMap untuk fitur numerik terpilih dan SalePrice
"""

# Atribut numerik terpilih
features = ['OverallQual', 'GrLivArea', 'GarageCars', 'YearBuilt', 'GarageArea', 'FullBath', 'TotalBsmtSF']
selected = ['SalePrice'] + features

# Korelasi
corr_matrix = clean_HousePrice[selected].corr(method='spearman')
# Membuat heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix antara SalePrice dan Fitur Terkait')
plt.tight_layout()
plt.show()

"""## Final Fitur"""

feature_selected

"""# Model Construction"""

# Verifikasi sudah tidak ada missing value
clean_HousePrice[feature_selected].info()

# Dataframe fitur
features = clean_HousePrice[feature_selected]
# Dataframe label
labels = clean_HousePrice["SalePrice"]

# Pembagian training set 60%
features_train, features_validation_test, labels_train, labels_validation_test = train_test_split(
    features, labels, test_size=0.4, random_state=42)
# Pembagian validation set 20% dan testing set 20%
features_validation, features_test, labels_validation, labels_test = train_test_split(
    features_validation_test, labels_validation_test, test_size=0.5, random_state=42)

"""Normalisasi dataset untuk model Multiple Linear Regression"""

# Pemanggilan library
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)

# Pembagian training set 60%
features_train_scale, features_validation_test_scale, labels_train_scale, labels_validation_test_scale = train_test_split(
    features_scaled, labels, test_size=0.4, random_state=42)
# Pembagian validation set 20% dan testing set 20%
features_validation_scale, features_test_scale, labels_validation_scale, labels_test_scale = train_test_split(
    features_validation_test_scale, labels_validation_test_scale, test_size=0.5, random_state=42)

"""## Multiple Linear Regression

### Ridge Scala
"""

# Ridge Regression
pipeline = Pipeline([
    ('ridge', Ridge(random_state=42))
])

# Parameter dan value yang digunakan pada eksperimen
param_grid = {
    'ridge__alpha': [0.01, 0.1, 1, 10, 100]
}

# GridSearchCV untuk parameter terbaik dengan r2
grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2')

# Fitting
grid_search.fit(features_train_scale, labels_train_scale)

# Parameter terbaik dan nilai r2
print("Best alpha:", grid_search.best_params_['ridge__alpha'])
print("R² score train test:", grid_search.best_score_)

# Function perhitungan MAPE
def mean_absolute_percentage_error(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    # Hindari pembagian dengan nol
    non_zero = y_true != 0
    return np.mean(np.abs((y_true[non_zero] - y_pred[non_zero]) / y_true[non_zero])) * 100

# Pembangunan model ridge dari best parameter
ridge_model = Ridge(alpha=100, random_state=42)
ridge_model.fit(features_train_scale, labels_train_scale)

# Prediksi menggunakan validation set
y_pred = ridge_model.predict(features_validation_scale)
mape = mean_absolute_percentage_error(labels_validation_scale, y_pred)

# Evaluasi hasil validation set
print("Validation set R²:", r2_score(labels_validation_scale, y_pred))
print("Validation set RMSE:", mean_squared_error(labels_validation_scale, y_pred))
print(f"Validation set MAPE: {mape:.2f}%")

"""### Lasso Scala"""

# Lasso Regression
pipeline = Pipeline([
    ('lasso', Lasso(random_state=42))
])

# Parameter dan value yang digunakan pada eksperimen
param_grid = {
    'lasso__alpha': [0.001, 0.01, 0.1, 1, 10]
}

# GridSearchCV untuk parameter terbaik dengan r2
grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2')

# Fitting
grid_search.fit(features_train_scale, labels_train_scale)

# Parameter terbaik dan nilai r2
print("Best alpha:", grid_search.best_params_['lasso__alpha'])
print("R² score train test:", grid_search.best_score_)

# Pembangunan model lasso dari best parameter
lasso_model = Lasso(alpha=10, random_state=42)
lasso_model.fit(features_train_scale, labels_train_scale)

# Prediksi menggunakan validation set
y_pred = lasso_model.predict(features_validation_scale)
mape = mean_absolute_percentage_error(labels_validation_scale, y_pred)

# Evaluasi hasil validation set
print("Validation set R²:", r2_score(labels_validation_scale, y_pred))
print("Validation set RMSE:", mean_squared_error(labels_validation_scale, y_pred))
print(f"Validation set MAPE: {mape:.2f}%")

"""## Gradient Boosting"""

# Gradient Boosting Regressor
gbr = GradientBoostingRegressor(random_state=42)

# Hyperparameter grid
param_grid = {
    'n_estimators': [50, 75, 100, 200],
    'learning_rate': [0.05, 0.1, 0.5, 0.7],
    'max_depth': [3, 5, 7],
    'subsample': [0.8, 1.0]
}

# GridSearchCV untuk parameter terbaik dengan r2
grid_search = GridSearchCV(
    estimator=gbr,
    param_grid=param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1,
    verbose=1
)

# Fitting
grid_search.fit(features_train, labels_train)

# Parameter terbaik dan nilai r2
best_gbr = grid_search.best_estimator_
y_pred = best_gbr.predict(features_train)
r2 = r2_score(labels_train, y_pred)

print("Best Parameters:", grid_search.best_params_)
print(f"R² score train test: {r2}")

# Prediksi menggunakan validation set
y_pred = best_gbr.predict(features_validation)
r2 = r2_score(labels_validation, y_pred)
rmse = np.sqrt(mean_squared_error(labels_validation, y_pred))
mape = mean_absolute_percentage_error(labels_validation, y_pred)

# Evaluasi hasil validation set
print(f"Validation R²: {r2}")
print(f"Validation RMSE: {rmse}")
print(f"Validation setMAPE: {mape:.2f}%")

"""## XGBoost Regressor"""

# XGBoost Regression
xgb = XGBRegressor(objective='reg:squarederror', random_state=42)

# Hyperparameter grid
param_grid = {
    'n_estimators': [50, 75, 100, 200],
    'learning_rate': [0.05, 0.1, 0.5, 0.7],
    'max_depth': [3, 5, 7],
    'min_split_loss': [1, 2, 4],
    'reg_lambda': [0, 0.5, 1]
}

# GridSearchCV untuk parameter terbaik dengan r2
grid_search = GridSearchCV(
    estimator=xgb,
    param_grid=param_grid,
    cv=5,
    scoring='r2',
    verbose=1,
    n_jobs=-1
)

# Fitting
grid_search.fit(features_train, labels_train)

# Parameter terbaik dan nilai r2
best_xgb = grid_search.best_estimator_
y_pred = best_xgb.predict(features_train)
r2 = r2_score(labels_train, y_pred)

print("Best Parameters:", grid_search.best_params_)
print(f"R² score train test: {r2}")

# Prediksi menggunakan validation set
y_pred = best_xgb.predict(features_validation)
r2 = r2_score(labels_validation, y_pred)
rmse = np.sqrt(mean_squared_error(labels_validation, y_pred))
mape = mean_absolute_percentage_error(labels_validation, y_pred)

# Evaluasi hasil validation set
print(f"Validation set R²: {r2}")
print(f"Validation set RMSE: {rmse}")
print(f"Validation set MAPE: {mape:.2f}%")

"""# Evaluation Model

Evaluasi model berdasarkan Testing Set.

## Ridge
"""

# Evaluasi performa
y_pred = ridge_model.predict(features_test_scale)
r2 = r2_score(labels_test_scale, y_pred)
rmse = np.sqrt(mean_squared_error(labels_test_scale, y_pred))
mape = mean_absolute_percentage_error(labels_test_scale, y_pred)
print(f"Testing set R²: {r2}")
print(f"Testing set RMSE: {rmse}")
print(f"Testing set MAPE: {mape:.2f}%")

# Scatter plot: aktual vs prediksi
plt.figure(figsize=(8, 6))
sns.scatterplot(x=labels_test_scale, y=y_pred)
plt.xlabel("Actual SalePrice")
plt.ylabel("Predicted SalePrice")
plt.title("Actual vs Predicted SalePrice (Ridge Regression)")
plt.plot([labels_test_scale.min(), labels_test_scale.max()],
        [labels_test_scale.min(), labels_test_scale.max()],
        'r--')  # garis diagonal
plt.grid(True)
plt.show()

# Residual Plot
residuals = labels_test_scale - y_pred
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel("Predicted SalePrice")
plt.ylabel("Residuals")
plt.title("Residuals vs Predicted (Ridge Regression)")
plt.grid(True)
plt.show()

# Distribusi Residual
plt.figure(figsize=(8, 6))
sns.histplot(residuals, kde=True, bins=30)
plt.title("Distribution of Residuals (Ridge Regression)")
plt.xlabel("Error")
plt.ylabel("Frequency")
plt.grid(True)
plt.show()

"""## Lasso"""

# Evaluasi performa
y_pred = lasso_model.predict(features_test_scale)
r2 = r2_score(labels_test_scale, y_pred)
rmse = np.sqrt(mean_squared_error(labels_test_scale, y_pred))
mape = mean_absolute_percentage_error(labels_test_scale, y_pred)
print(f"Testing set R²: {r2}")
print(f"Testing set RMSE: {rmse}")
print(f"Testing set MAPE: {mape:.2f}%")

# Scatter plot: aktual vs prediksi
plt.figure(figsize=(8, 6))
sns.scatterplot(x=labels_test_scale, y=y_pred)
plt.xlabel("Actual SalePrice")
plt.ylabel("Predicted SalePrice")
plt.title("Actual vs Predicted SalePrice (Lasso Regression)")
plt.plot([labels_test_scale.min(), labels_test_scale.max()],
        [labels_test_scale.min(), labels_test_scale.max()],
        'r--')  # garis diagonal
plt.grid(True)
plt.show()

# Residual Plot
residuals = labels_test_scale - y_pred
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel("Predicted SalePrice")
plt.ylabel("Residuals")
plt.title("Residuals vs Predicted (Lasso Regression)")
plt.grid(True)
plt.show()

# Distribusi Residual
plt.figure(figsize=(8, 6))
sns.histplot(residuals, kde=True, bins=30)
plt.title("Distribution of Residuals (Lasso Regression)")
plt.xlabel("Error")
plt.ylabel("Frequency")
plt.grid(True)
plt.show()

"""## Gradient"""

# Evaluasi performa
y_pred = best_gbr.predict(features_test)
r2 = r2_score(labels_test, y_pred)
rmse = np.sqrt(mean_squared_error(labels_test, y_pred))
mape = mean_absolute_percentage_error(labels_test, y_pred)
print(f"Testing set R²: {r2}")
print(f"Testing set RMSE: {rmse}")
print(f"Testing set MAPE: {mape:.2f}%")

# Scatter plot: aktual vs prediksi
plt.figure(figsize=(8, 6))
sns.scatterplot(x=labels_test, y=y_pred)
plt.xlabel("Actual SalePrice")
plt.ylabel("Predicted SalePrice")
plt.title("Actual vs Predicted SalePrice (Gradient Boosting Regression)")
plt.plot([labels_test.min(), labels_test.max()],
        [labels_test.min(), labels_test.max()],
        'r--')  # garis diagonal
plt.grid(True)
plt.show()

# Residual Plot
residuals = labels_test - y_pred
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel("Predicted SalePrice")
plt.ylabel("Residuals")
plt.title("Residuals vs Predicted (Gradient Boosting Regression)")
plt.grid(True)
plt.show()

# Distribusi Residual
plt.figure(figsize=(8, 6))
sns.histplot(residuals, kde=True, bins=30)
plt.title("Distribution of Residuals (Gradient Boosting Regression)")
plt.xlabel("Error")
plt.ylabel("Frequency")
plt.grid(True)
plt.show()

"""## XGBoost"""

# Evaluasi performa
y_pred = best_xgb.predict(features_test)
r2 = r2_score(labels_test, y_pred)
rmse = np.sqrt(mean_squared_error(labels_test, y_pred))
mape = mean_absolute_percentage_error(labels_test, y_pred)
print(f"Testing set R²: {r2}")
print(f"Testing set RMSE: {rmse}")
print(f"Testing set MAPE: {mape:.2f}%")

# Scatter plot: aktual vs prediksi
plt.figure(figsize=(8, 6))
sns.scatterplot(x=labels_test, y=y_pred)
plt.xlabel("Actual SalePrice")
plt.ylabel("Predicted SalePrice")
plt.title("Actual vs Predicted SalePrice (XGBoost Regression)")
plt.plot([labels_test.min(), labels_test.max()],
        [labels_test.min(), labels_test.max()],
        'r--')  # garis diagonal
plt.grid(True)
plt.show()

# Residual Plot
residuals = labels_test - y_pred
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel("Predicted SalePrice")
plt.ylabel("Residuals")
plt.title("Residuals vs Predicted (XGBoost Regression)")
plt.grid(True)
plt.show()

# Distribusi Residual
plt.figure(figsize=(8, 6))
sns.histplot(residuals, kde=True, bins=30)
plt.title("Distribution of Residuals (XGBoost Regression)")
plt.xlabel("Error")
plt.ylabel("Frequency")
plt.grid(True)
plt.show()

"""# Kesimpulan

Berdasarkan hasil pembangunan 4 model, model terbaik adalah model XGBoost Regression.
"""

import joblib
joblib.dump(best_xgb, 'best_xgb_model.pkl')